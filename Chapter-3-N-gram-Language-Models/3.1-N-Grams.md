## Section 3.1 N-Grams

P(w|h) is unable to give good predictions in most cases due to the limited size of corpus even if it is the web

probability of sentence or sequence of words:
P(W) = P(w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>...w<sub>n</sub>)

probability of an upcoming word:
P(w<sub>5</sub>|w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>, w<sub>4</sub>)

a model that computes either of those is called a **language model**

Using the chain rule, the probability of the sequence of words can be expressed as:
P(W) = P(w<sub>1</sub>) * P(w<sub>2</sub>|w<sub>1</sub>) * P(w<sub>3</sub>|w<sub>1</sub>, w<sub>2</sub>) * ... * P(w<sub>n</sub>|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n-1</sub>)
