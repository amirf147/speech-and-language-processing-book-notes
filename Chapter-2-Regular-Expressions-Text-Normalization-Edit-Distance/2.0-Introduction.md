Speech and Language Processing

# Chapter 2: Regular Expressions, Text Normalization, Edit Distance

## Text Normalization
Converting to more convenient standard form

### separating out words = tokenization
An emoticon or hashtag can be tokenized

### Lemmatization
task of determining that two words have the same root despite their surface differences.
sang song and sings with lemma sing
lemmatizer maps from all these to sing

### Stemming
simpler version where we just strip suffix is from the end of the word

### Segmentation
breaking up text into individual sentences using cues like .!

### Edit Distance
a metric that measures how similar two strings are based on the number of edits like insertions deletions substitution it takes to change one string into the other.
