## Chapter 2: Regular Expressions, Text Normalization, Edit Distance

### Section 2.5: Word Tokenization
Tokenization is the task segmenting out the text into words

#### Section 2.5.1: Top-down (rule-based) tokenization
Need to consider commas, periods another punctuation inside and outside of words, numbers, prices, urls, email addresses.

**Clitic**:
    - ne'er, we're need to be expanded
    - it's the part of the word that doesn't make sense on its own it only makes sense when it's attached to another word
